{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import matplotlib.pyplot as plt\n",
    "import custom_vgg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    img = skimage.io.imread(path)\n",
    "    img = img / 255.0\n",
    "    # add another dimension to make it a batch , bacause our vgg19 def takes a batch\n",
    "    img = img.reshape((1,)+img.shape)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 337, 236, 3)\n"
     ]
    }
   ],
   "source": [
    "path = './vd.jpg'\n",
    "img = skimage.io.imread(path)\n",
    "img = img / 255.0\n",
    "img = np.expand_dims(img,0)\n",
    "print(img.shape)\n",
    "# show image\n",
    "# skimage.io.imshow(img)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/04006/zhuode93/maverick/dlproj2/trainable-neural-style/tensorflow_vgg/vgg19.npy\n",
      "npy file loaded\n"
     ]
    }
   ],
   "source": [
    "sess=tf.Session()\n",
    "img_pl = tf.placeholder(tf.float32)\n",
    "vgg19factory = custom_vgg19.Vgg19Factory()\n",
    "vgg19 = vgg19factory.build(img_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 337, 236, 3)\n",
      "(1, 169, 118, 128)\n"
     ]
    }
   ],
   "source": [
    "print(img.shape)\n",
    "conv21feat = sess.run(vgg19.conv2_1, feed_dict={img_pl:img})\n",
    "print(conv21feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gram_matrix(feat_map):\n",
    "    assert isinstance(feat_map, tf.Tensor)\n",
    "    shape = tf.shape(feat_map)\n",
    "    h, w, ch = tf.cast(shape[1], tf.float32), tf.cast(shape[2], tf.float32), shape[3]\n",
    "    size = h*w\n",
    "    F = tf.reshape(feat_map, [-1, ch])\n",
    "    \n",
    "    # TODO: if m<n, compute feat_map*feat_map, else compute feat_map'*feat_map \n",
    "    gram = tf.matmul(F, F, True) / (size**2)\n",
    "    return gram\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_gen = tf.Variable(tf.truncated_normal(img.shape, mean=0.5, stddev=0.25))\n",
    "vgg19_for_img_gen = vgg19factory.build(img_gen)\n",
    "\n",
    "G = gram_matrix(vgg19.conv3_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial style loss = 91256.062500\n",
      "initial content loss = 12901.880859\n"
     ]
    }
   ],
   "source": [
    "# compute gram_matrix for the style image\n",
    "style_gram = tf.Variable(G,validate_shape=False,trainable=False)\n",
    "\n",
    "styleimg_content = tf.Variable(vgg19.conv2_1,validate_shape=False, trainable=False)\n",
    "\n",
    "sess.run(tf.initialize_all_variables(), feed_dict={img_pl:img})\n",
    "\n",
    "gen_gram = gram_matrix(vgg19_for_img_gen.conv3_1)\n",
    "shape = tf.cast(tf.shape(gen_gram), tf.float32)\n",
    "style_loss = tf.nn.l2_loss(gen_gram - style_gram) # / shape[0] / shape[1] # uncomment this will cause img_gen\n",
    "                        # stay being white-noise. see what is the magnitude of the cost of stylenet?\n",
    "[style_loss_np, shapenp] =sess.run([style_loss, shape])\n",
    "print('initial style loss = %f' % style_loss_np)\n",
    "\n",
    "shape = tf.cast(tf.shape(vgg19_for_img_gen.conv2_1), tf.float32)\n",
    "nElement = tf.reduce_prod(shape)\n",
    "content_loss = tf.nn.l2_loss(styleimg_content - vgg19_for_img_gen.conv2_1) / nElement \n",
    "[content_loss_np, shapenp] =sess.run([content_loss, shape])\n",
    "print('initial content loss = %f' % content_loss_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220.353\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.RMSPropOptimizer(0.005)\n",
    "total_loss = style_loss + content_loss\n",
    "train_op = optimizer.minimize(total_loss)\n",
    "# start optimization\n",
    "iter = 0\n",
    "MAX_ITER = 1000\n",
    "sess.run(tf.initialize_all_variables(), feed_dict={img_pl:img})\n",
    "while iter < MAX_ITER:\n",
    "    sess.run(train_op)\n",
    "    iter += 1\n",
    "print(sess.run(total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.62544727, 1.5940531)\n",
      "(1.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "img_gen_np = np.squeeze(sess.run(img_gen), 0)\n",
    "minv,maxv = np.min(img_gen_np), np.max(img_gen_np)\n",
    "print(minv,maxv) # TODO: I don't know why minv<0, maxv>1,\n",
    "     # and this make imshow shows a more \"grey\" image compared to the original one\n",
    "img_gen_np =  (img_gen_np-minv)/(maxv-minv)\n",
    "skimage.io.imshow(img_gen_np)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 337, 236, 3)\n",
      "(0.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "print img.shape\n",
    "print(  np.min(img[0,:,:,:]), np.max(img[0,:,:,:]))\n",
    "skimage.io.imshow(img[0,:,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
