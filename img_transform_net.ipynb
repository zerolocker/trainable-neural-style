{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import matplotlib.pyplot as plt\n",
    "import custom_vgg19\n",
    "import Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "input_shape = [BATCH_SIZE, 256, 256, 3]\n",
    "STYLE_LAYERS = ('conv1_1', 'conv2_1', 'conv3_1', 'conv4_1')\n",
    "CONTENT_LAYER = 'conv4_2' # I can get good result with relu3_2 with slow neural-style with same weight. maybe I can try here\n",
    "CONTENT_WEIGHT = 7.5\n",
    "STYLE_WEIGHT = 100\n",
    "NEW_H, NEW_W = 256, 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "styleimg = Lib.load_image_as_batch_with_optional_resize('./picasso_selfport1907.jpg')\n",
    "print(styleimg.shape)\n",
    "contentimg = Lib.load_image_as_batch_with_optional_resize('./brad_pitt.jpg', newH=NEW_H, newW=NEW_W)\n",
    "print(contentimg.shape)\n",
    "\n",
    "# show image\n",
    "# skimage.io.imshow(contentimg[0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we can go ahead and extract content features and style features\n",
    "sess=tf.Session()\n",
    "styleimg_ph = tf.placeholder(tf.float32, shape=styleimg.shape)\n",
    "vgg19factory = custom_vgg19.Vgg19Factory()\n",
    "vgg19_pretrain = vgg19factory.build(styleimg_ph)\n",
    "\n",
    "# sanity check: make sure the layer names are correct\n",
    "try:\n",
    "    style_layers_pretrain = [getattr(vgg19_pretrain, name) for name in STYLE_LAYERS]\n",
    "    content_layer_pretrain = getattr(vgg19_pretrain, CONTENT_LAYER)\n",
    "except Exception as ex:\n",
    "    print ex,  \"incorrect layer name. Note: all layer named 'conv' is relu. e.g. 'conv1_1' is actually 'relu1_1'\"\n",
    "    sys.exit(1)\n",
    "\n",
    "styleimg_grams = [gram_matrix(l) for l in style_layers_pretrain]\n",
    "styleimg_grams_np = sess.run(styleimg_grams, feed_dict={styleimg_ph:styleimg})\n",
    "# contentimg_feat_map_np = sess.run(content_layer_pretrain, feed_dict={styleimg_ph:contentimg}) # just for debug propose. It's not slow neural-style, so there is no target content img during training\n",
    "styleimg_grams = [tf.constant(g, dtype=tf.float32) for g in styleimg_grams_np]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# construct img transfrom network\n",
    "img_train = tf.placeholder(tf.float32, input_shape)\n",
    "img_pred = Lib.buildTransformNet(img_train, expected_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# construct vgg19 to extract pred img's content & style\n",
    "vgg19_pred = vgg19factory.build(img_pred)  # make sure pred img have VGG19's desired scale and range([0,1])\n",
    "style_layers_pred = [getattr(vgg19_pred, name) for name in STYLE_LAYERS]\n",
    "content_layer_pred = getattr(vgg19_pred, CONTENT_LAYER)\n",
    "\n",
    "# construct vgg19 to extract train img's content as ground truth\n",
    "vgg19_extractContent = vgg19factory.build(img_train)    # TODO ugly solution! \n",
    "   # So, in total I have to build 3 same vgg19 just because I have different input Tensor \n",
    "    # (two are placeholders of different shapes; the other one is the predicted image). Any way to avoid this?\n",
    "content_layer_target = getattr(vgg19_extractContent, CONTENT_LAYER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "style_losses = [Lib.compute_style_loss(styleimg_grams[i], style_layers_pred[i]) for i in xrange(len(styleimg_grams))]\n",
    "content_loss = Lib.compute_content_loss(content_layer_target, content_layer_pred)\n",
    "loss = STYLE_WEIGHT * reduce(tf.add, style_losses) + CONTENT_WEIGHT * content_loss\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "** integration test: read some pictures and overfit the network to it **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "test_batch_f = filter(lambda s:s.startswith('COCO'), os.listdir('data'))[:BATCH_SIZE]\n",
    "assert len(test_batch_f) == BATCH_SIZE, ('not enough files', len(test_batch_f))\n",
    "test_batch_np = np.zeros(input_shape)\n",
    "for i in xrange(BATCH_SIZE):\n",
    "    test_batch_np[i] = load_image_as_batch_with_optional_resize('data/'+test_batch_f[i], newH=NEW_H, newW=NEW_W)\n",
    "\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_ITER = 200\n",
    "for i in xrange(MAX_ITER):\n",
    "    l = sess.run([train_op, loss]+ style_losses +[content_loss], feed_dict={img_train: test_batch_np})\n",
    "    print l[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_pred_np = sess.run(img_pred, feed_dict={img_train: test_batch_np})\n",
    "\n",
    "f,axarr=plt.subplots(3,3, figsize=(10,10))\n",
    "for i in xrange(3):  \n",
    "    for j in xrange(3):\n",
    "        img = np.clip(img_pred_np[i*3+j],0,1)\n",
    "        axarr[i][j].imshow(img)\n",
    "        axarr[i][j].xaxis.set_visible(False)\n",
    "        axarr[i][j].yaxis.set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f,axarr=plt.subplots(3,3)\n",
    "for i in xrange(3): \n",
    "    for j in xrange(3): \n",
    "        axarr[i][j].imshow(test_batch_np[i*3+j])\n",
    "        plt.imsave(str(i*3+j)+)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saver=tf.train.Saver()\n",
    "saver.save(sess, 'chkpt/cur.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
